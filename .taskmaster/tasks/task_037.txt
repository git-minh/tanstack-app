# Task ID: 37
# Title: Streaming Responses Implementation
# Status: done
# Dependencies: 36
# Priority: medium
# Description: Implement polling-based streaming for real-time message display as tokens arrive
# Details:
Create convex/chatStreaming.ts with startStreamingMessage, appendStreamChunk, finalizeStreamMessage mutations. Update chat action to batch-update message every 50ms or 10 tokens during generation. Update chat-messages.tsx to poll for updates and display partial content with typing indicator.

# Test Strategy:
Test streaming with various message lengths, verify no duplicate tokens, test interruption handling, measure latency

# Subtasks:
## 1. Create streaming mutations [done]
### Dependencies: None
### Description: Build mutations for managing streaming message state
### Details:
Create convex/chatStreaming.ts with: startStreamingMessage mutation (creates placeholder message with isStreaming=true flag), appendStreamChunk mutation (appends tokens to message content), finalizeStreamMessage mutation (marks message as complete, sets isStreaming=false, adds final token count). All mutations validate user owns the session.

## 2. Update chat action for streaming [done]
### Dependencies: 37.1
### Description: Modify sendChatMessage action to support token-by-token streaming
### Details:
Update convex/chat.ts sendChatMessage action: 1) Call startStreamingMessage to create placeholder, 2) Use Azure OpenAI streaming API (stream: true), 3) Accumulate tokens in batches (every 10 tokens or 50ms), 4) Call appendStreamChunk mutation for each batch, 5) After stream completes, call finalizeStreamMessage, 6) Handle errors and cleanup incomplete streams, 7) Return messageId for frontend polling.

## 3. Implement frontend streaming polling [done]
### Dependencies: 37.2
### Description: Add polling logic to chat-messages.tsx for real-time updates
### Details:
Update components/features/chat/chat-messages.tsx: Detect messages with isStreaming=true flag, poll for updates every 100ms using useQuery with refetchInterval, display partial content with typing indicator (...), stop polling when isStreaming=false, show "Generating..." status while streaming, auto-scroll to bottom as content updates, handle interrupted streams gracefully.

